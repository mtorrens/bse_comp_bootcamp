{"nbformat":4,"nbformat_minor":0,"metadata":{"celltoolbar":"Slideshow","kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"},"name":"pandas.ipynb","toc":{"base_numbering":1,"nav_menu":{},"number_sections":false,"sideBar":true,"skip_h1_title":true,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{},"toc_section_display":true,"toc_window_display":false},"colab":{"name":"pandas.ipynb","provenance":[],"collapsed_sections":["wI1WlerwALaz","nJDHof78ALa0","rzaKWLHHALa0","2jWPVrYIALa0","ejpFxIrPALa0","mDfxKbZiALa0","Uuq10UkdALa0","LlvxHSGNALa0","ovq98xvVALa0","GOQ1rmJxALa1","LaecTofyALa1","PPxL5V5_ALa1","xa2noi0gALa1"],"toc_visible":true}},"cells":[{"cell_type":"markdown","metadata":{"id":"qXAF4khtALay"},"source":["<img src = \"https://github.com/barcelonagse-datascience/academic_files/raw/master/bgsedsc_0.jpg\">"]},{"cell_type":"markdown","metadata":{"ein.tags":"worksheet-0","id":"D3ipVggrALay"},"source":["## Numpy: NUMerical PYthon \n","\n","<img src = \"https://numpy.org/images/logos/numpy.svg\" width=30%>\n","\n","This is Python's stack for scientific computing. The fundamental new data type is that of a **numpy array**, Python's matrix(tensor)-type object, which is used in the majority of Python's modules for Data Analysis, Statistics and Machine Learning  - for example in order to feed data into `sklearn` functions\n","\n","numpy arrays contain data all of the same type (*dtype*), numerical of many types or boolean\n","\n","The coordinates are known as axes"]},{"cell_type":"code","metadata":{"autoscroll":false,"ein.hycell":false,"ein.tags":"worksheet-0","id":"rpgZbUTLALay"},"source":["# import module \n","import numpy as np"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"ein.tags":"worksheet-0","id":"bxhVqC4iALay"},"source":["To create an array we use the np.array() function"]},{"cell_type":"code","metadata":{"autoscroll":false,"ein.hycell":false,"ein.tags":"worksheet-0","id":"VQz_djKnALay"},"source":["# creating an array\n","a = np.array([[1, 2, 3, 4, 5, 6], \n","              [42, 53, 43 ,62, 7, 4], \n","              [-3, -1, -4 ,-8, -52, -4], \n","              [10, 0, 4 , 1, 0, 1]])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"ein.tags":"worksheet-0","id":"vxHguvWEALay"},"source":["We can access the elements in an array using multi-index notation, familiar in small variations in many computing environments and languages - with the usual Pythonic conventions, e.g., counting starts from 0, slicing a:b is inclusive:exclusive, negative indices, etc\n","\n","What do you think the following piece of code does? \n","\n","```python\n","print(a[-2:,[2,4]])\n","```"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZjB2Ulhx_GaX","executionInfo":{"status":"ok","timestamp":1608213366256,"user_tz":-60,"elapsed":572,"user":{"displayName":"Joan Verdú","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghq6Zm9ACo3kD6kZhp6ZuWkYJqG_DQfPoIV1Ues=s64","userId":"17893353067607712705"}},"outputId":"020c8603-f56f-47fa-9f22-025684379b22"},"source":["print(a[-2:,[2,4]])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[[ -4 -52]\n"," [  4   0]]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"ein.tags":"worksheet-0","id":"yCJ1iMiPALay"},"source":["### Array attributes\n","\n","The array data type has its own attributes. Some worth highlighting are:\n","\n","+ Shape\n","```python\n","arrayname.shape # returns the shape as tuple, e.g. (4,6)\n","arrayname.reshape(arg) # returns a new array with the same data as those in arrayname but organized in different shape - read carefully defaults\n","```\n","+ Aggregations\n","```python\n","arrayname.function(arg) # e.g. function could be sum, max, min, etc. args can be used to specify operation over all elements, or for an axis, etc  - this is much more efficient than looping\n","```\n","+ Linear algebra\n","```python\n","arrayname.transpose(arg)  # transpose - even for multi-d arrays\n","arrayname.diagonal(arg) # diagonal elements as array\n","arrayname.dot(anotherarray) # dot product\n","```\n"]},{"cell_type":"markdown","metadata":{"ein.tags":"worksheet-0","id":"T116lxuIALay"},"source":["## Array operations\n","\n","Remember that to concatenate two lists in Python, we could use the \"+\" operator. \n","\n","This is not the case in Numpy!\n","\n","Mathematical symbols take on mathematical meanings in Numpy. Thus, the \"+\" operator between two Numpy Arrays actually just attempts to add them together, elementwise."]},{"cell_type":"code","metadata":{"autoscroll":false,"ein.hycell":false,"ein.tags":"worksheet-0","colab":{"base_uri":"https://localhost:8080/"},"id":"h84uKpg5ALay","executionInfo":{"status":"ok","timestamp":1608213595345,"user_tz":-60,"elapsed":636,"user":{"displayName":"Joan Verdú","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghq6Zm9ACo3kD6kZhp6ZuWkYJqG_DQfPoIV1Ues=s64","userId":"17893353067607712705"}},"outputId":"9dbf0f62-eaca-422b-ee19-27e2addb5bee"},"source":["# Numpy array addition: \n","\n","a,b = np.array([1,2,3]), np.array([4,5,6])\n","a + b"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([5, 7, 9])"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"autoscroll":false,"ein.hycell":false,"ein.tags":"worksheet-0","colab":{"base_uri":"https://localhost:8080/"},"id":"dul0iaGtALaz","executionInfo":{"status":"ok","timestamp":1606739018708,"user_tz":-60,"elapsed":1447,"user":{"displayName":"Joan Verdú","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghq6Zm9ACo3kD6kZhp6ZuWkYJqG_DQfPoIV1Ues=s64","userId":"17893353067607712705"}},"outputId":"29e2090e-cad2-4e22-e765-492566e1dbba"},"source":["# Numpy array concatenation: \n","\n","np.concatenate([a,b])"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([1, 2, 3, 4, 5, 6])"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"markdown","metadata":{"ein.tags":"worksheet-0","id":"GYpejdvbALaz"},"source":["# Data analysis with Python: PANDAS\n","\n","PANDAS: Panel Data Structures \n","\n","<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/2/22/Pandas_mark.svg/245px-Pandas_mark.svg.png\" width=15%>\n","\n","This is the module in Python for doing rectangular-data management, analysis and plotting.\n","\n","The first set of tools are to read and write. "]},{"cell_type":"markdown","metadata":{"ein.tags":"worksheet-0","id":"HtMzjXjKALaz"},"source":["## Loading data into Python \n","\n","See [IO DOC](https://pandas.pydata.org/pandas-docs/stable/io.html) in Python for more information\n","\n","Lets load our first dataset (and load all we need to get working!)"]},{"cell_type":"code","metadata":{"autoscroll":false,"ein.hycell":false,"ein.tags":"worksheet-0","colab":{"base_uri":"https://localhost:8080/","height":195},"id":"voK-eHrLALaz","executionInfo":{"status":"ok","timestamp":1608213850862,"user_tz":-60,"elapsed":561,"user":{"displayName":"Joan Verdú","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghq6Zm9ACo3kD6kZhp6ZuWkYJqG_DQfPoIV1Ues=s64","userId":"17893353067607712705"}},"outputId":"c7a4e34a-1ca0-43d3-df47-85abb8087126"},"source":["import pandas as pd\n","\n","# load a dataframe from disk\n","# if loading from URL\n","tips = pd.read_csv(\"https://raw.githubusercontent.com/barcelonagse-datascience/academic_files/master/data/tips.csv\")\n","\n","# if loading locally\n","# tips = pd.read_csv(\"../../Data/tips.csv\")\n","tips.head(5)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>total_bill</th>\n","      <th>tip</th>\n","      <th>sex</th>\n","      <th>smoker</th>\n","      <th>day</th>\n","      <th>time</th>\n","      <th>size</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>16.99</td>\n","      <td>1.01</td>\n","      <td>Female</td>\n","      <td>No</td>\n","      <td>Sun</td>\n","      <td>Dinner</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>10.34</td>\n","      <td>1.66</td>\n","      <td>Male</td>\n","      <td>No</td>\n","      <td>Sun</td>\n","      <td>Dinner</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>21.01</td>\n","      <td>3.50</td>\n","      <td>Male</td>\n","      <td>No</td>\n","      <td>Sun</td>\n","      <td>Dinner</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>23.68</td>\n","      <td>3.31</td>\n","      <td>Male</td>\n","      <td>No</td>\n","      <td>Sun</td>\n","      <td>Dinner</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>24.59</td>\n","      <td>3.61</td>\n","      <td>Female</td>\n","      <td>No</td>\n","      <td>Sun</td>\n","      <td>Dinner</td>\n","      <td>4</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   total_bill   tip     sex smoker  day    time  size\n","0       16.99  1.01  Female     No  Sun  Dinner     2\n","1       10.34  1.66    Male     No  Sun  Dinner     3\n","2       21.01  3.50    Male     No  Sun  Dinner     3\n","3       23.68  3.31    Male     No  Sun  Dinner     2\n","4       24.59  3.61  Female     No  Sun  Dinner     4"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"markdown","metadata":{"ein.tags":"worksheet-0","id":"8CBfSIKCALaz"},"source":["## Series and DataFrame\n","\n","These are the two basic data formats in PANDAS, the equivalent of column and rectangular data structures, as in linear algebra (vector/matrix) but equipped with several attributes invaluable for data management and analysis\n","\n","In the *tips* example, the variable \"tips\" is a DataFrame, while any individual column would be a Series. \n","\n"]},{"cell_type":"markdown","metadata":{"ein.tags":"worksheet-0","id":"RtQj1gP3ALaz"},"source":["## Series \n","\n","This is a 1-d data structure with *values* accessed via their index. \n","\n","Unlike in raw Python or Numpy, however, Series indices can be made up of either: \n","+ *numbers*: which could be ordered and contiguous like a Python list, but don't have to be! \n","+ *strings*: essentially labels, like the keys in a dictionary\n","\n","Although typically a series is obtained by reading a dataset from an external file or when doing operations on dataframes, we can still define one manually by specifying the values and the indices. \n","\n","Let's do this an get an insight into how it works"]},{"cell_type":"code","metadata":{"autoscroll":false,"ein.hycell":false,"ein.tags":"worksheet-0","id":"H9qg_ZReALaz"},"source":["# here no indices are specified, there are defaults\n","my_series = pd.Series([1, 15, -5, None, 4, 123, 0, 78, 0, 5, -4])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"autoscroll":false,"ein.hycell":false,"ein.tags":"worksheet-0","colab":{"base_uri":"https://localhost:8080/"},"id":"23duzOXDALaz","executionInfo":{"status":"ok","timestamp":1608213969454,"user_tz":-60,"elapsed":610,"user":{"displayName":"Joan Verdú","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghq6Zm9ACo3kD6kZhp6ZuWkYJqG_DQfPoIV1Ues=s64","userId":"17893353067607712705"}},"outputId":"c8bcb988-8819-49d5-be05-6ae1711f4633"},"source":["# Accessing a certain value via the index\n","\n","my_series[0]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1.0"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"code","metadata":{"autoscroll":false,"ein.hycell":false,"ein.tags":"worksheet-0","colab":{"base_uri":"https://localhost:8080/"},"id":"IRcxYz48ALaz","executionInfo":{"status":"ok","timestamp":1608213982259,"user_tz":-60,"elapsed":594,"user":{"displayName":"Joan Verdú","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghq6Zm9ACo3kD6kZhp6ZuWkYJqG_DQfPoIV1Ues=s64","userId":"17893353067607712705"}},"outputId":"c243b021-9c74-4859-d152-72d392a733b8"},"source":["# Note that there are a bunch of attributes.\n","# .values returns a numpy ndarray of the values! \n","\n","my_series.values"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([  1.,  15.,  -5.,  nan,   4., 123.,   0.,  78.,   0.,   5.,  -4.])"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"code","metadata":{"autoscroll":false,"ein.hycell":false,"ein.tags":"worksheet-0","colab":{"base_uri":"https://localhost:8080/"},"id":"0ppuCtMDALaz","executionInfo":{"status":"ok","timestamp":1608213991573,"user_tz":-60,"elapsed":608,"user":{"displayName":"Joan Verdú","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghq6Zm9ACo3kD6kZhp6ZuWkYJqG_DQfPoIV1Ues=s64","userId":"17893353067607712705"}},"outputId":"5477fa78-f717-4b8b-e5f7-5f598132e2c9"},"source":["# Take a look at the index. What type is it? \n","# You convert itto a numpy ndarray by adding \".values\" again!\n","\n","my_series.index"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["RangeIndex(start=0, stop=11, step=1)"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"code","metadata":{"autoscroll":false,"ein.hycell":false,"ein.tags":"worksheet-0","colab":{"base_uri":"https://localhost:8080/"},"id":"D7HguxcXALaz","executionInfo":{"status":"ok","timestamp":1608214102180,"user_tz":-60,"elapsed":565,"user":{"displayName":"Joan Verdú","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghq6Zm9ACo3kD6kZhp6ZuWkYJqG_DQfPoIV1Ues=s64","userId":"17893353067607712705"}},"outputId":"9ac660e4-eec4-4025-9c30-ac909089b913"},"source":["# You can overwrite the index directly: \n","\n","my_series.index = [\"om\",\"ir\",\"os\",\"pap\",\"pas\",\"pil\",\"io\",\"po\",\"ulos\",\"is\",\"best\"]\n","\n","my_series"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["om        1.0\n","ir       15.0\n","os       -5.0\n","pap       NaN\n","pas       4.0\n","pil     123.0\n","io        0.0\n","po       78.0\n","ulos      0.0\n","is        5.0\n","best     -4.0\n","dtype: float64"]},"metadata":{"tags":[]},"execution_count":19}]},{"cell_type":"markdown","metadata":{"ein.tags":"worksheet-0","id":"wI1WlerwALaz"},"source":["## iloc\n","\n","Accessing values via the index can be very useful, but sometimes you want to access the values as though they were a Python list. In other words \"I want the first value!\", without having to know the name of the label. \n","\n","This can be achieved with .iloc: \n","\n","```python\n","my_series.iloc[0]\n","```"]},{"cell_type":"code","metadata":{"autoscroll":false,"ein.hycell":false,"ein.tags":"worksheet-0","colab":{"base_uri":"https://localhost:8080/"},"id":"DXKAUnxOALaz","executionInfo":{"status":"ok","timestamp":1608214106226,"user_tz":-60,"elapsed":779,"user":{"displayName":"Joan Verdú","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghq6Zm9ACo3kD6kZhp6ZuWkYJqG_DQfPoIV1Ues=s64","userId":"17893353067607712705"}},"outputId":"f83963de-4184-4339-b858-a5b6edc3bc89"},"source":["# Series that have string indices can also be accessed via a RangeIndex\n","# (which is similar to the index of a regular Python list)\n","\n","my_series.iloc[0], my_series[\"om\"]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1.0, 1.0)"]},"metadata":{"tags":[]},"execution_count":20}]},{"cell_type":"code","metadata":{"autoscroll":false,"ein.hycell":false,"ein.tags":"worksheet-0","colab":{"base_uri":"https://localhost:8080/"},"id":"yEjmG0FOALaz","executionInfo":{"status":"ok","timestamp":1608214167405,"user_tz":-60,"elapsed":641,"user":{"displayName":"Joan Verdú","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghq6Zm9ACo3kD6kZhp6ZuWkYJqG_DQfPoIV1Ues=s64","userId":"17893353067607712705"}},"outputId":"92ba30ac-24af-4283-92ec-7aa0da92bbe2"},"source":["# Note that indices can get moved around, by sorting for example!\n","# iloc gives you the element you would get if the Series\n","# was a list and you were giving it the index:\n","\n","# This just resets the index to be as we found it originally\n","my_series = my_series.reset_index(drop=True)\n","\n","x = my_series.sort_values()\n","\n","x[0], x.iloc[0]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1.0, -5.0)"]},"metadata":{"tags":[]},"execution_count":21}]},{"cell_type":"markdown","metadata":{"ein.tags":"worksheet-0","id":"mzjvRGE6ALaz"},"source":["## Operations with series\n","\n","Because Series are Numpy arrays behind the scenes, we can compute element-wise functions on one series or several series at the same time. The result is another series with data type depending on the type of operations performed. \n","\n","For example, what do you think the following piece of code will do: "]},{"cell_type":"code","metadata":{"autoscroll":false,"ein.hycell":false,"ein.tags":"worksheet-0","id":"U4vEEfuJALaz"},"source":["series1 = pd.Series([1,3,5,7])\n","series2 = pd.Series([0,10,-1,6])\n","\n","series3 = 2*series1 + abs(series2)\n","\n","series4 = series1 > series2 \n","\n","# Take a look at the different Series objects!"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"ein.tags":"worksheet-0","id":"Rzkx0AekALaz"},"source":["## Data alignment \n","\n","What goes on in the previous examples is more subtle than it looks. How does Python know which elements from each series to join in the required operation together?  \n","\n","What happens is that the indices happened to be the same. So when we ask something like \n","\n","```python\n","series3 = series1 + series2 \n","```\n","\n","Python looks for entries in each series with the same index and then does an elementwise summation that it stores in a like-wise index in Series 3. \n","\n","Consider instead the following example "]},{"cell_type":"code","metadata":{"autoscroll":false,"ein.hycell":false,"ein.tags":"worksheet-0","id":"2cDb80wgALaz"},"source":["series1 = pd.Series([1,10],index=[\"om\",\"iros\"])\n","series2 = pd.Series([4,-1],index=[\"pap\",\"as\"])\n","series3 = series1 + series2"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VVy3MrzZC9fF","executionInfo":{"status":"ok","timestamp":1608214375438,"user_tz":-60,"elapsed":654,"user":{"displayName":"Joan Verdú","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghq6Zm9ACo3kD6kZhp6ZuWkYJqG_DQfPoIV1Ues=s64","userId":"17893353067607712705"}},"outputId":"50f06822-8cdd-4a32-bfad-99f264c1d126"},"source":["series3"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["as     NaN\n","iros   NaN\n","om     NaN\n","pap    NaN\n","dtype: float64"]},"metadata":{"tags":[]},"execution_count":27}]},{"cell_type":"markdown","metadata":{"ein.tags":"worksheet-0","id":"_pm9gUMxALaz"},"source":["This aspect makes it very easy to work with series that we have sorted or manipulated otherwise; there is always the address to access a value. This helps prevent accidentally combining values we didn't mean to combine!"]},{"cell_type":"markdown","metadata":{"ein.tags":"worksheet-0","id":"0MDQtBZfALaz"},"source":["## Basic information retrieval with series\n","\n","+ Accessing single elements\n","+ Slicing; accessing a set of elements\n","+ Filtering; selection by  boolean index\n","\n","Recalling that operations on Series returns Series, the big news here is that we can access values in a Series by specifying \n","\n","+ single index\n","+ a slice (a:b for integers a,b) \n","+ list (or Numpy Array or Series) of index labels\n","+ a boolean Series (also called a _boolean mask_) \n","\n","Interesting: the result of any such retrieval (except for a single index) is a series itself!"]},{"cell_type":"code","metadata":{"autoscroll":false,"ein.hycell":false,"ein.tags":"worksheet-0","id":"0luZtKcYALaz"},"source":["# accesing by list of index labels\n","\n","my_series.index = [\"om\",\"ir\",\"os\",\"pap\",\"pas\",\"pil\",\"io\",\"po\",\"ulos\",\"is\",\"best\"]\n","x = my_series[[\"om\",\"pap\"]]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RH9fBbPyDcv6","executionInfo":{"status":"ok","timestamp":1608214520573,"user_tz":-60,"elapsed":561,"user":{"displayName":"Joan Verdú","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghq6Zm9ACo3kD6kZhp6ZuWkYJqG_DQfPoIV1Ues=s64","userId":"17893353067607712705"}},"outputId":"a163dda6-4b43-42ff-a08b-b840732acd76"},"source":["my_series"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["om        1.0\n","ir       15.0\n","os       -5.0\n","pap       NaN\n","pas       4.0\n","pil     123.0\n","io        0.0\n","po       78.0\n","ulos      0.0\n","is        5.0\n","best     -4.0\n","dtype: float64"]},"metadata":{"tags":[]},"execution_count":30}]},{"cell_type":"code","metadata":{"autoscroll":false,"ein.hycell":false,"ein.tags":"worksheet-0","colab":{"base_uri":"https://localhost:8080/"},"id":"nxe5Sf4KALaz","executionInfo":{"status":"ok","timestamp":1608214557644,"user_tz":-60,"elapsed":623,"user":{"displayName":"Joan Verdú","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghq6Zm9ACo3kD6kZhp6ZuWkYJqG_DQfPoIV1Ues=s64","userId":"17893353067607712705"}},"outputId":"ca6a4c36-6d49-4912-b948-450445ee2e0f"},"source":["# getting a boolean-valued series by checking a condition\n","\n","choose = my_series == 0.0\n","choose"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["om      False\n","ir      False\n","os      False\n","pap     False\n","pas     False\n","pil     False\n","io       True\n","po      False\n","ulos     True\n","is      False\n","best    False\n","dtype: bool"]},"metadata":{"tags":[]},"execution_count":31}]},{"cell_type":"code","metadata":{"autoscroll":false,"ein.hycell":false,"ein.tags":"worksheet-0","id":"IMY3weyPALaz","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608214585378,"user_tz":-60,"elapsed":627,"user":{"displayName":"Joan Verdú","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghq6Zm9ACo3kD6kZhp6ZuWkYJqG_DQfPoIV1Ues=s64","userId":"17893353067607712705"}},"outputId":"f78c46db-4ea6-4f7b-93f6-f81dcdaa5770"},"source":["# Notice the index of x is a SUBSET of the index of \"my_series\"\n","# This can be useful when needing to relate values back to the original \"my_series\"!\n","\n","x = my_series[choose]\n","x"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["io      0.0\n","ulos    0.0\n","dtype: float64"]},"metadata":{"tags":[]},"execution_count":32}]},{"cell_type":"markdown","metadata":{"ein.tags":"worksheet-0","id":"vFZ8ZcpzALaz"},"source":["## Filtering via boolean masks\n","\n","We often use boolean masks to filter data in Pandas. Series that are of type \"bool\" thus take on special significance: we use them a lot!\n","\n","We also get special boolean algebra operators to use in Numpy/Pandas, distinct from the and/or/not you will use in regular Python: \n","\n","\n","```python\n","& # AND\n","| # OR\n","~ # NOT\n","```"]},{"cell_type":"markdown","metadata":{"id":"EbyrPtUs4iDq"},"source":["### Exercise 1"]},{"cell_type":"code","metadata":{"autoscroll":false,"ein.hycell":false,"ein.tags":"worksheet-0","id":"E7eXTB7cALaz"},"source":["# Challenge: \n","\n","# Filter \"my_series\" to be all the elements that are NOT\n","# equal to 0, using a boolean mask you create\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"ein.tags":"worksheet-0","id":"zdJ275sQALaz"},"source":["## Coding and managing missing values\n","\n","A series object in PANDAS can deal with maybe the most important type of data of all for data analysis: missing data! \n","\n","We already see very naturally how data management leads to missing data rather immediately. Recall the earlier attempt to sum up to Series\n","\n","```python\n","series3 = series1 + series2\n","print(series3)\n","as     NaN\n","iros   NaN\n","om     NaN\n","pap    NaN\n","dtype: float64\n","```\n","What happened there is that in the operation labels could not be matched, so pandas tried to sum a numeric value with a missing value, the result of which is a missing value!"]},{"cell_type":"markdown","metadata":{"ein.tags":"worksheet-0","id":"QvBzekNmALa0"},"source":["The way to manually specify in PANDAS that a value is missing is to use use None, as below: \n","\n","```python\n","temp = pd.Series([1,None,2])\n","print(temp)\n","0    1.0\n","1    NaN\n","2    2.0\n","dtype: float64\n","```\n","If the Series is numeric, Pandas will caste it to numpy.float64 type and convert the None values to Numpy NaN values (Not a Number). If the Series is of type \"object\" (arbitrary Python objects), it will keep the values as None.\n","\n","We can create *boolean masks* on the basis of such values. The way to identify NaN or None values in a Series is to use either of the equivalent two attributes\n","\n","```python\n","seriesname.isna()\n","seriesname.isnull()\n","```\n","\n","Either returns a boolean-valued series that we can use then for selecting and operating on NaN or the rest of the values. The opposite also exists: \n","\n","```python\n","seriesname.notna()\n","seriesname.notnull()\n","```\n"]},{"cell_type":"markdown","metadata":{"id":"U56JodpP4i5c"},"source":["### Exercise 2"]},{"cell_type":"code","metadata":{"autoscroll":false,"ein.hycell":false,"ein.tags":"worksheet-0","id":"pmWmxf_WALa0"},"source":["# Challenge: \n","# Get a list of names, without the Null values!\n","\n","# The Pandas way: \n","# 1. Create a boolean mask by using the .notna() method.\n","# 2. Use the mask to subset the Series.\n","\n","names = pd.Series(['foo','bar',None,'baz','qux',None])\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"ein.tags":"worksheet-0","id":"OVvqsAVDALa0"},"source":["## Highlighting some important series attributes & methods\n","\n","As usual one should explore the attributes of any python object one ends up working with. We have already accessed the seriesname.index and seriesname.value\n","\n","Some other (among many!) that are worth highlighting: \n","\n","+ .map\n","+ .corr \n","+ .describe\n","+ .hist\n","+ .plot\n","+ .size\n","+ .value_counts\n","+ .sort_values"]},{"cell_type":"markdown","metadata":{"id":"RxhUrXtq4qKb"},"source":["### Exercise 3"]},{"cell_type":"code","metadata":{"autoscroll":false,"ein.hycell":false,"ein.tags":"worksheet-0","id":"sMe-pFYTALa0"},"source":["# Challenge: \n","\n","# Use the \"map\" method to create a new series with each element\n","# lowercased. Create your own function to do the operation. \n","# Missing values should stay missing!\n","\n","\n","def lower(s):\n","    # Your code here\n","    # HINT: delete the \"pass\" when your done\n","    # HINT2: handle None values!\n","    pass\n","\n","\n","names = pd.Series(['Foo', 'BAR', None, 'foo', None, 'bar', 'bAR', 'foo', None])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"autoscroll":false,"ein.hycell":false,"ein.tags":"worksheet-0","id":"IQFopKMGALa0"},"source":["# Challenge: \n","\n","# Using the series from above, now lowercased, count the occurences of each name\n","# Hint: It's simple, just use .value_counts()!\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"ein.tags":"worksheet-0","id":"I7bBC8KZALa0"},"source":["## Dataframes\n","\n","This is PANDAS model for rectangular data, operationally is like a dictionary of series; each column of the dataframe is a series object, and clearly comes with all the attributes/methods of a series\n","\n","An implication of the above is that within each column the data type is common; across columns of course this can change\n","\n","Let's see an example right away "]},{"cell_type":"code","metadata":{"autoscroll":false,"ein.hycell":false,"ein.tags":"worksheet-0","colab":{"base_uri":"https://localhost:8080/","height":343},"id":"Q20y3ncBALa0","executionInfo":{"status":"ok","timestamp":1608215058361,"user_tz":-60,"elapsed":806,"user":{"displayName":"Joan Verdú","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghq6Zm9ACo3kD6kZhp6ZuWkYJqG_DQfPoIV1Ues=s64","userId":"17893353067607712705"}},"outputId":"2ae68fdb-de7f-40fd-d5c9-ef3c8d0238a5"},"source":["tips=pd.read_csv(\"https://raw.githubusercontent.com/barcelonagse-datascience/academic_files/master/data/tips.csv\")\n","\n","#tips = pd.read_csv(\"../../Data/tips.csv\")\n","tips.head(10) # the first method of our dataframe object! "],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>total_bill</th>\n","      <th>tip</th>\n","      <th>sex</th>\n","      <th>smoker</th>\n","      <th>day</th>\n","      <th>time</th>\n","      <th>size</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>16.99</td>\n","      <td>1.01</td>\n","      <td>Female</td>\n","      <td>No</td>\n","      <td>Sun</td>\n","      <td>Dinner</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>10.34</td>\n","      <td>1.66</td>\n","      <td>Male</td>\n","      <td>No</td>\n","      <td>Sun</td>\n","      <td>Dinner</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>21.01</td>\n","      <td>3.50</td>\n","      <td>Male</td>\n","      <td>No</td>\n","      <td>Sun</td>\n","      <td>Dinner</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>23.68</td>\n","      <td>3.31</td>\n","      <td>Male</td>\n","      <td>No</td>\n","      <td>Sun</td>\n","      <td>Dinner</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>24.59</td>\n","      <td>3.61</td>\n","      <td>Female</td>\n","      <td>No</td>\n","      <td>Sun</td>\n","      <td>Dinner</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>25.29</td>\n","      <td>4.71</td>\n","      <td>Male</td>\n","      <td>No</td>\n","      <td>Sun</td>\n","      <td>Dinner</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>8.77</td>\n","      <td>2.00</td>\n","      <td>Male</td>\n","      <td>No</td>\n","      <td>Sun</td>\n","      <td>Dinner</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>26.88</td>\n","      <td>3.12</td>\n","      <td>Male</td>\n","      <td>No</td>\n","      <td>Sun</td>\n","      <td>Dinner</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>15.04</td>\n","      <td>1.96</td>\n","      <td>Male</td>\n","      <td>No</td>\n","      <td>Sun</td>\n","      <td>Dinner</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>14.78</td>\n","      <td>3.23</td>\n","      <td>Male</td>\n","      <td>No</td>\n","      <td>Sun</td>\n","      <td>Dinner</td>\n","      <td>2</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   total_bill   tip     sex smoker  day    time  size\n","0       16.99  1.01  Female     No  Sun  Dinner     2\n","1       10.34  1.66    Male     No  Sun  Dinner     3\n","2       21.01  3.50    Male     No  Sun  Dinner     3\n","3       23.68  3.31    Male     No  Sun  Dinner     2\n","4       24.59  3.61  Female     No  Sun  Dinner     4\n","5       25.29  4.71    Male     No  Sun  Dinner     4\n","6        8.77  2.00    Male     No  Sun  Dinner     2\n","7       26.88  3.12    Male     No  Sun  Dinner     4\n","8       15.04  1.96    Male     No  Sun  Dinner     2\n","9       14.78  3.23    Male     No  Sun  Dinner     2"]},"metadata":{"tags":[]},"execution_count":33}]},{"cell_type":"code","metadata":{"autoscroll":false,"ein.hycell":false,"ein.tags":"worksheet-0","colab":{"base_uri":"https://localhost:8080/"},"id":"KXf_6mJqALa0","executionInfo":{"status":"ok","timestamp":1608215112166,"user_tz":-60,"elapsed":641,"user":{"displayName":"Joan Verdú","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghq6Zm9ACo3kD6kZhp6ZuWkYJqG_DQfPoIV1Ues=s64","userId":"17893353067607712705"}},"outputId":"42755a19-de81-4802-ce50-ecea4ae8c89c"},"source":["# the other important attribute: name of rows and columns\n","print(tips.index)\n","tips.columns"],"execution_count":null,"outputs":[{"output_type":"stream","text":["RangeIndex(start=0, stop=244, step=1)\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["Index(['total_bill', 'tip', 'sex', 'smoker', 'day', 'time', 'size'], dtype='object')"]},"metadata":{"tags":[]},"execution_count":35}]},{"cell_type":"markdown","metadata":{"ein.tags":"worksheet-0","id":"Bk6-40h2ALa0"},"source":["## Accessing the series embedded within\n","\n","There are two way to access the information in the columns: \n","+ One is to give the name of the column as `dataframename.columnname` \n","   + This is not feasible when the name of the column coincides with an attribute or method of the dataframe, e.g. when a column is called \"size\"  \n","+ Another is as dataframename[\"columnname\"]\n","\n","Any of these calls returns a series object with the same index as the dataframe and the values of the column\n","\n","We can then work with the extracted series as usual. Hence you can understand what happens below \n","\n","```python\n","tips[\"size\"].corr(tips.tip)\n","```"]},{"cell_type":"markdown","metadata":{"ein.tags":"worksheet-0","id":"HW5b2Zc7ALa0"},"source":["In a similar fashion, we can access various columns at a time; we need to provide a list of column names in this case; the result is now a dataframe with the same index as the original and columns the chosen subset. We can then work with it using any of the dataframe attributes and methods we know. \n","\n","You can now guess what will happen below: \n","\n","```python\n","tips[[\"tip\",\"size\",\"sex\"]].tip.corr(tips[\"size\"])\n","\n","```\n","(not saying that this is a sensible code! just trying to make sure we understand the structure)"]},{"cell_type":"markdown","metadata":{"ein.tags":"worksheet-0","id":"nJDHof78ALa0"},"source":["## Accessing subsets of rows\n","\n","Now we are interested in a subset of rows. We can access rows by:\n","+ list of index labels \n","  ```python\n","  dataframename.loc[ [index1, index2, ...] ]\n","  ```\n","+ list of integer index location (i-loc) \n","  ```python\n","  dataframename.iloc[ [integer1, integer2, ...] ]\n","  ```\n","The output is:\n","+ a series, if a single column or row is chosen\n","+ a dataframe, with index label the chosen index labels and the same column names as the dataframe\n","\n","In the case of .iloc we can also use slices, as for example\n","```python\n","dataframename.iloc[3:5]\n","dataframename.iloc[3:5,:]\n","dataframename.iloc[3:5,-2:]\n","```\n","\n","Note: loc/iloc are also used to access a subset of rows AND columns at the same time. See examples below!"]},{"cell_type":"code","metadata":{"autoscroll":false,"ein.hycell":false,"ein.tags":"worksheet-0","colab":{"base_uri":"https://localhost:8080/","height":106},"id":"0ibxkCrlALa0","executionInfo":{"status":"ok","timestamp":1608215501493,"user_tz":-60,"elapsed":594,"user":{"displayName":"Joan Verdú","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghq6Zm9ACo3kD6kZhp6ZuWkYJqG_DQfPoIV1Ues=s64","userId":"17893353067607712705"}},"outputId":"25f6c9ec-fcd8-4ae0-b260-adbda966edc4"},"source":["# Accessing rows AND columns!\n","# Example of 2-dimension loc\n","\n","tips.loc[[1,3], ['sex', 'smoker']]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sex</th>\n","      <th>smoker</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>Male</td>\n","      <td>No</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Male</td>\n","      <td>No</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    sex smoker\n","1  Male     No\n","3  Male     No"]},"metadata":{"tags":[]},"execution_count":40}]},{"cell_type":"code","metadata":{"autoscroll":false,"ein.hycell":false,"ein.tags":"worksheet-0","colab":{"base_uri":"https://localhost:8080/","height":106},"id":"6oPAKIDIALa0","executionInfo":{"status":"ok","timestamp":1608215588064,"user_tz":-60,"elapsed":572,"user":{"displayName":"Joan Verdú","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghq6Zm9ACo3kD6kZhp6ZuWkYJqG_DQfPoIV1Ues=s64","userId":"17893353067607712705"}},"outputId":"99d00954-4f64-4e2a-e22d-35a575a9ea54"},"source":["# Accessing rows AND columns!\n","# Example of 2-dimensional iloc\n","\n","tips.iloc[[1,3], 2:5]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sex</th>\n","      <th>smoker</th>\n","      <th>day</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>Male</td>\n","      <td>No</td>\n","      <td>Sun</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Male</td>\n","      <td>No</td>\n","      <td>Sun</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    sex smoker  day\n","1  Male     No  Sun\n","3  Male     No  Sun"]},"metadata":{"tags":[]},"execution_count":43}]},{"cell_type":"markdown","metadata":{"id":"JjaBHeel5GNx"},"source":["### Exercise 4"]},{"cell_type":"code","metadata":{"autoscroll":false,"ein.hycell":false,"ein.tags":"worksheet-0","id":"GxwsU-JWALa0"},"source":["# Challenge:\n","\n","# Using the tips dataframe, create a new one that contains the \n","# information contained in all rows between the 20th (inclusive) \n","# and the 45th (exclusive) and only the columns: tip, sex, day"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"ein.tags":"worksheet-0","id":"tb2T_h4XALa0"},"source":["Note that certain operations are exchangeable: the 3rd element of column \"sex\" can be obtained with either of the following ways: \n","```python\n","tips.sex[2] #access col as series, then the 3rd element of that\n","tips.loc[2,\"sex\"] #access the entry in dataframe by giving the index labels of row and col (recall here index labels coincide with numerical indices\n","tips.loc[2][\"sex\"] #accessing the whole row as a series, then using the column name as index label\n","```\n","etc\n"]},{"cell_type":"markdown","metadata":{"ein.tags":"worksheet-0","id":"rzaKWLHHALa0"},"source":["## Filtering\n","\n","As with series, we can use a boolean-valued series to index a dataframe provided the share the same index labels. The simplest instance of this is to use series produced as boolean masks of columns of the dataframe. The output of this *filtering* operation is a dataframe with subset of rows corresponding to the True values in the boolean mask. \n","\n","For example, for the tips data, what does the following produce? \n","```python\n","tips[tips.sex == \"Male\"] \n","```\n","\n","Recall that the boolean operators are \n","```python\n","& # AND\n","| # OR\n","~ # NOT\n","\n","```"]},{"cell_type":"markdown","metadata":{"ein.tags":"worksheet-0","id":"2jWPVrYIALa0"},"source":["## Statistics and computations\n","\n","dataframe comes with several attributes for computing column-wise statistics and summaries. We highlight some \n","```python\n",".boxplot # check out the \"by = \" option!\n",".corrwith & .corr # within and across dataframes!\n",".dot \n",".mean/median/max/quantile/sum etc\n",".sample \n",".sort_values\n",".unique\n","```"]},{"cell_type":"markdown","metadata":{"id":"g84VxfdP5KKQ"},"source":["### Exercise 5"]},{"cell_type":"code","metadata":{"autoscroll":false,"ein.hycell":false,"ein.tags":"worksheet-0","id":"Bb68HjxOALa0"},"source":["# Challenge:\n","\n","# Using the tips dataframe, calculate the correlation between\n","# tip and size for only Male clients during Dinner. \n","\n","# HINT: Remember that \"size\" cannot be accessed via dot notation, as it's an \n","# attribute of the series!"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"ein.tags":"worksheet-0","id":"ejpFxIrPALa0"},"source":["## GroupBy\n","\n","This dataframe method groups the dataframe according to the values of a column, treating them as categorical values; it returns a groupby object!\n","\n","Groupby objects are useful, but can feel a bit opaque. Let's play around with them a bit: "]},{"cell_type":"code","metadata":{"autoscroll":false,"ein.hycell":false,"ein.tags":"worksheet-0","colab":{"base_uri":"https://localhost:8080/"},"id":"6PJLKjD8ALa0","executionInfo":{"status":"ok","timestamp":1608215908582,"user_tz":-60,"elapsed":612,"user":{"displayName":"Joan Verdú","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghq6Zm9ACo3kD6kZhp6ZuWkYJqG_DQfPoIV1Ues=s64","userId":"17893353067607712705"}},"outputId":"858a4b6f-59a6-4ae9-fd81-fdc3554872d7"},"source":["# Group tips dataframe by size of table\n","by_size = tips.groupby(\"size\")\n","\n","by_size"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<pandas.core.groupby.generic.DataFrameGroupBy object at 0x7f5a95de79e8>"]},"metadata":{"tags":[]},"execution_count":44}]},{"cell_type":"code","metadata":{"autoscroll":false,"ein.hycell":false,"ein.tags":"worksheet-0","colab":{"base_uri":"https://localhost:8080/"},"id":"WRo9tl3OALa0","executionInfo":{"status":"ok","timestamp":1608215916022,"user_tz":-60,"elapsed":681,"user":{"displayName":"Joan Verdú","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghq6Zm9ACo3kD6kZhp6ZuWkYJqG_DQfPoIV1Ues=s64","userId":"17893353067607712705"}},"outputId":"7752f833-299d-4923-a890-e5f3abef8bd3"},"source":["# If we coerce it to a list, we see something interesting: \n","# It's basically a list of tuples! \n","# The first element is the \"category\" variable, the second\n","# is a datafame. \n","\n","list(by_size)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[(1,      total_bill   tip     sex smoker   day    time  size\n","  67         3.07  1.00  Female    Yes   Sat  Dinner     1\n","  82        10.07  1.83  Female     No  Thur   Lunch     1\n","  111        7.25  1.00  Female     No   Sat  Dinner     1\n","  222        8.58  1.92    Male    Yes   Fri   Lunch     1),\n"," (2,      total_bill   tip     sex smoker   day    time  size\n","  0         16.99  1.01  Female     No   Sun  Dinner     2\n","  3         23.68  3.31    Male     No   Sun  Dinner     2\n","  6          8.77  2.00    Male     No   Sun  Dinner     2\n","  8         15.04  1.96    Male     No   Sun  Dinner     2\n","  9         14.78  3.23    Male     No   Sun  Dinner     2\n","  ..          ...   ...     ...    ...   ...     ...   ...\n","  237       32.83  1.17    Male    Yes   Sat  Dinner     2\n","  240       27.18  2.00  Female    Yes   Sat  Dinner     2\n","  241       22.67  2.00    Male    Yes   Sat  Dinner     2\n","  242       17.82  1.75    Male     No   Sat  Dinner     2\n","  243       18.78  3.00  Female     No  Thur  Dinner     2\n","  \n","  [156 rows x 7 columns]),\n"," (3,      total_bill    tip     sex smoker   day    time  size\n","  1         10.34   1.66    Male     No   Sun  Dinner     3\n","  2         21.01   3.50    Male     No   Sun  Dinner     3\n","  16        10.33   1.67  Female     No   Sun  Dinner     3\n","  17        16.29   3.71    Male     No   Sun  Dinner     3\n","  18        16.97   3.50  Female     No   Sun  Dinner     3\n","  19        20.65   3.35    Male     No   Sat  Dinner     3\n","  35        24.06   3.60    Male     No   Sat  Dinner     3\n","  36        16.31   2.00    Male     No   Sat  Dinner     3\n","  37        16.93   3.07  Female     No   Sat  Dinner     3\n","  38        18.69   2.31    Male     No   Sat  Dinner     3\n","  39        31.27   5.00    Male     No   Sat  Dinner     3\n","  40        16.04   2.24    Male     No   Sat  Dinner     3\n","  48        28.55   2.05    Male     No   Sun  Dinner     3\n","  64        17.59   2.64    Male     No   Sat  Dinner     3\n","  65        20.08   3.15    Male     No   Sat  Dinner     3\n","  71        17.07   3.00  Female     No   Sat  Dinner     3\n","  102       44.30   2.50  Female    Yes   Sat  Dinner     3\n","  112       38.07   4.00    Male     No   Sun  Dinner     3\n","  114       25.71   4.00  Female     No   Sun  Dinner     3\n","  129       22.82   2.18    Male     No  Thur   Lunch     3\n","  146       18.64   1.36  Female     No  Thur   Lunch     3\n","  152       17.26   2.74    Male     No   Sun  Dinner     3\n","  162       16.21   2.00  Female     No   Sun  Dinner     3\n","  165       24.52   3.48    Male     No   Sun  Dinner     3\n","  170       50.81  10.00    Male    Yes   Sat  Dinner     3\n","  182       45.35   3.50    Male    Yes   Sun  Dinner     3\n","  186       20.90   3.50  Female    Yes   Sun  Dinner     3\n","  188       18.15   3.50  Female    Yes   Sun  Dinner     3\n","  189       23.10   4.00    Male    Yes   Sun  Dinner     3\n","  200       18.71   4.00    Male    Yes  Thur   Lunch     3\n","  205       16.47   3.23  Female    Yes  Thur   Lunch     3\n","  206       26.59   3.41    Male    Yes   Sat  Dinner     3\n","  210       30.06   2.00    Male    Yes   Sat  Dinner     3\n","  214       28.17   6.50  Female    Yes   Sat  Dinner     3\n","  223       15.98   3.00  Female     No   Fri   Lunch     3\n","  231       15.69   3.00    Male    Yes   Sat  Dinner     3\n","  238       35.83   4.67  Female     No   Sat  Dinner     3\n","  239       29.03   5.92    Male     No   Sat  Dinner     3),\n"," (4,      total_bill   tip     sex smoker   day    time  size\n","  4         24.59  3.61  Female     No   Sun  Dinner     4\n","  5         25.29  4.71    Male     No   Sun  Dinner     4\n","  7         26.88  3.12    Male     No   Sun  Dinner     4\n","  11        35.26  5.00  Female     No   Sun  Dinner     4\n","  13        18.43  3.00    Male     No   Sun  Dinner     4\n","  23        39.42  7.58    Male     No   Sat  Dinner     4\n","  25        17.81  2.34    Male     No   Sat  Dinner     4\n","  31        18.35  2.50    Male     No   Sat  Dinner     4\n","  33        20.69  2.45  Female     No   Sat  Dinner     4\n","  44        30.40  5.60    Male     No   Sun  Dinner     4\n","  47        32.40  6.00    Male     No   Sun  Dinner     4\n","  52        34.81  5.20  Female     No   Sun  Dinner     4\n","  54        25.56  4.34    Male     No   Sun  Dinner     4\n","  56        38.01  3.00    Male    Yes   Sat  Dinner     4\n","  59        48.27  6.73    Male     No   Sat  Dinner     4\n","  63        18.29  3.76    Male    Yes   Sat  Dinner     4\n","  77        27.20  4.00    Male     No  Thur   Lunch     4\n","  85        34.83  5.17  Female     No  Thur   Lunch     4\n","  95        40.17  4.73    Male    Yes   Fri  Dinner     4\n","  116       29.93  5.07    Male     No   Sun  Dinner     4\n","  119       24.08  2.92  Female     No  Thur   Lunch     4\n","  153       24.55  2.00    Male     No   Sun  Dinner     4\n","  154       19.77  2.00    Male     No   Sun  Dinner     4\n","  157       25.00  3.75  Female     No   Sun  Dinner     4\n","  159       16.49  2.00    Male     No   Sun  Dinner     4\n","  160       21.50  3.50    Male     No   Sun  Dinner     4\n","  167       31.71  4.50    Male     No   Sun  Dinner     4\n","  180       34.65  3.68    Male    Yes   Sun  Dinner     4\n","  183       23.17  6.50    Male    Yes   Sun  Dinner     4\n","  197       43.11  5.00  Female    Yes  Thur   Lunch     4\n","  204       20.53  4.00    Male    Yes  Thur   Lunch     4\n","  207       38.73  3.00    Male    Yes   Sat  Dinner     4\n","  211       25.89  5.16    Male    Yes   Sat  Dinner     4\n","  212       48.33  9.00    Male     No   Sat  Dinner     4\n","  219       30.14  3.09  Female    Yes   Sat  Dinner     4\n","  227       20.45  3.00    Male     No   Sat  Dinner     4\n","  230       24.01  2.00    Male    Yes   Sat  Dinner     4),\n"," (5,      total_bill   tip     sex smoker   day    time  size\n","  142       41.19  5.00    Male     No  Thur   Lunch     5\n","  155       29.85  5.14  Female     No   Sun  Dinner     5\n","  185       20.69  5.00    Male     No   Sun  Dinner     5\n","  187       30.46  2.00    Male    Yes   Sun  Dinner     5\n","  216       28.15  3.00    Male    Yes   Sat  Dinner     5),\n"," (6,      total_bill  tip     sex smoker   day    time  size\n","  125       29.80  4.2  Female     No  Thur   Lunch     6\n","  141       34.30  6.7    Male     No  Thur   Lunch     6\n","  143       27.05  5.0  Female     No  Thur   Lunch     6\n","  156       48.17  5.0    Male     No   Sun  Dinner     6)]"]},"metadata":{"tags":[]},"execution_count":45}]},{"cell_type":"code","metadata":{"autoscroll":false,"ein.hycell":false,"ein.tags":"worksheet-0","colab":{"base_uri":"https://localhost:8080/"},"id":"_Rjca0i_ALa0","executionInfo":{"status":"ok","timestamp":1608215981760,"user_tz":-60,"elapsed":700,"user":{"displayName":"Joan Verdú","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghq6Zm9ACo3kD6kZhp6ZuWkYJqG_DQfPoIV1Ues=s64","userId":"17893353067607712705"}},"outputId":"e22a6ce7-8695-4265-f60e-34dce7b6cdb2"},"source":["# We can iterate through the groupby just like we would a list of tuples!\n","\n","\n","for sex,data in tips.groupby(\"sex\"):\n","    print(sex)\n","    print(data.mean())"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Female\n","total_bill    18.056897\n","tip            2.833448\n","size           2.459770\n","dtype: float64\n","Male\n","total_bill    20.744076\n","tip            3.089618\n","size           2.630573\n","dtype: float64\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"ein.tags":"worksheet-0","id":"mDfxKbZiALa0"},"source":["## Why do we groupby? \n","\n","We group by to perform _some_ operation on each group. To _map_ over the groups, applying a function to each element! \n","\n","Very often this function is itself an aggregation (reduction). We want to somehow aggregate each group into a value or set of values that _describe_ the group!\n","\n","How do we apply functions to each element of a groupby? We use a handy method called \".apply\"!"]},{"cell_type":"code","metadata":{"autoscroll":false,"ein.hycell":false,"ein.tags":"worksheet-0","colab":{"base_uri":"https://localhost:8080/"},"id":"r6GNzT0MALa0","executionInfo":{"status":"ok","timestamp":1608216073143,"user_tz":-60,"elapsed":652,"user":{"displayName":"Joan Verdú","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghq6Zm9ACo3kD6kZhp6ZuWkYJqG_DQfPoIV1Ues=s64","userId":"17893353067607712705"}},"outputId":"cd6ba2dd-dd33-4041-b8dd-30445748b587"},"source":["# Get the maximum bill by gender: \n","\n","def max_bill(df):\n","    return df.total_bill.max()\n","\n","tips.groupby(\"sex\").apply(max_bill)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["sex\n","Female    44.30\n","Male      50.81\n","dtype: float64"]},"metadata":{"tags":[]},"execution_count":47}]},{"cell_type":"markdown","metadata":{"id":"rGJPkfNA5TKR"},"source":["### Exercise 6"]},{"cell_type":"code","metadata":{"autoscroll":false,"ein.hycell":false,"ein.tags":"worksheet-0","id":"dnn4c4MMALa0"},"source":["# Challenge: \n","\n","# Get the second largest bill by gender!\n","# HINT: use sort_values and iloc!"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"ein.tags":"worksheet-0","id":"Uuq10UkdALa0"},"source":["## Built-in Aggregations in groupby\n","\n","Many aggregation functions that exist on Series and DataFrames (mean, max, min, etc.) can be called directly via the groupby object: \n","\n","```python\n","tips.groupby(\"sex\").max()\n","tips.groupby(\"sex\").mean()\n","```"]},{"cell_type":"markdown","metadata":{"id":"dnMAlhPw5hXp"},"source":["### Exercise 7"]},{"cell_type":"code","metadata":{"autoscroll":false,"ein.hycell":false,"ein.tags":"worksheet-0","colab":{"base_uri":"https://localhost:8080/"},"id":"LKhd-4SPALa0","executionInfo":{"status":"ok","timestamp":1606739019136,"user_tz":-60,"elapsed":1771,"user":{"displayName":"Joan Verdú","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghq6Zm9ACo3kD6kZhp6ZuWkYJqG_DQfPoIV1Ues=s64","userId":"17893353067607712705"}},"outputId":"ab1c237f-ad5a-4b0c-b3f1-22454d5c8842"},"source":["# Challenge: \n","# What is the mean tip, per day, for male vs. female?\n","\n","\n","def day_mean(df):\n","    # Hint: you will need to group by \"day\"\n","    # in this function, then get the mean tip. \n","    pass\n","\n","\n","tips.groupby(\"sex\").apply(day_mean)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["Empty DataFrame\n","Columns: []\n","Index: []"]},"metadata":{"tags":[]},"execution_count":33}]},{"cell_type":"markdown","metadata":{"ein.tags":"worksheet-0","id":"mx9Ii-d8ALa0"},"source":["\n","## Multiple Groupby!\n","\n","That groupby induction that we just performed, it's quite a common use-case! So there's an even easier way to do it in Pandas. \n","\n","We can group by more than one column! \n","\n","For example the task we accomplished above could also be derived as: \n","\n","```python\n","tips.groupby([\"sex\",\"day\"]).tip.mean()\n","```"]},{"cell_type":"code","metadata":{"autoscroll":false,"ein.hycell":false,"ein.tags":"worksheet-0","colab":{"base_uri":"https://localhost:8080/"},"id":"PUrs68HgALa0","executionInfo":{"status":"ok","timestamp":1608216216828,"user_tz":-60,"elapsed":575,"user":{"displayName":"Joan Verdú","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghq6Zm9ACo3kD6kZhp6ZuWkYJqG_DQfPoIV1Ues=s64","userId":"17893353067607712705"}},"outputId":"ef97e602-f33a-43dc-e6dc-10a7c5dc93f3"},"source":["# Take a look at the structure of the multiple groupby!\n","\n","list(tips.groupby([\"sex\", \"day\"]))"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[(('Female', 'Fri'),      total_bill   tip     sex smoker  day    time  size\n","  92         5.75  1.00  Female    Yes  Fri  Dinner     2\n","  93        16.32  4.30  Female    Yes  Fri  Dinner     2\n","  94        22.75  3.25  Female     No  Fri  Dinner     2\n","  100       11.35  2.50  Female    Yes  Fri  Dinner     2\n","  101       15.38  3.00  Female    Yes  Fri  Dinner     2\n","  221       13.42  3.48  Female    Yes  Fri   Lunch     2\n","  223       15.98  3.00  Female     No  Fri   Lunch     3\n","  225       16.27  2.50  Female    Yes  Fri   Lunch     2\n","  226       10.09  2.00  Female    Yes  Fri   Lunch     2),\n"," (('Female', 'Sat'),      total_bill   tip     sex smoker  day    time  size\n","  21        20.29  2.75  Female     No  Sat  Dinner     2\n","  22        15.77  2.23  Female     No  Sat  Dinner     2\n","  29        19.65  3.00  Female     No  Sat  Dinner     2\n","  32        15.06  3.00  Female     No  Sat  Dinner     2\n","  33        20.69  2.45  Female     No  Sat  Dinner     4\n","  37        16.93  3.07  Female     No  Sat  Dinner     3\n","  57        26.41  1.50  Female     No  Sat  Dinner     2\n","  66        16.45  2.47  Female     No  Sat  Dinner     2\n","  67         3.07  1.00  Female    Yes  Sat  Dinner     1\n","  71        17.07  3.00  Female     No  Sat  Dinner     3\n","  72        26.86  3.14  Female    Yes  Sat  Dinner     2\n","  73        25.28  5.00  Female    Yes  Sat  Dinner     2\n","  74        14.73  2.20  Female     No  Sat  Dinner     2\n","  102       44.30  2.50  Female    Yes  Sat  Dinner     3\n","  103       22.42  3.48  Female    Yes  Sat  Dinner     2\n","  104       20.92  4.08  Female     No  Sat  Dinner     2\n","  109       14.31  4.00  Female    Yes  Sat  Dinner     2\n","  111        7.25  1.00  Female     No  Sat  Dinner     1\n","  168       10.59  1.61  Female    Yes  Sat  Dinner     2\n","  169       10.63  2.00  Female    Yes  Sat  Dinner     2\n","  209       12.76  2.23  Female    Yes  Sat  Dinner     2\n","  213       13.27  2.50  Female    Yes  Sat  Dinner     2\n","  214       28.17  6.50  Female    Yes  Sat  Dinner     3\n","  215       12.90  1.10  Female    Yes  Sat  Dinner     2\n","  219       30.14  3.09  Female    Yes  Sat  Dinner     4\n","  229       22.12  2.88  Female    Yes  Sat  Dinner     2\n","  238       35.83  4.67  Female     No  Sat  Dinner     3\n","  240       27.18  2.00  Female    Yes  Sat  Dinner     2),\n"," (('Female', 'Sun'),      total_bill   tip     sex smoker  day    time  size\n","  0         16.99  1.01  Female     No  Sun  Dinner     2\n","  4         24.59  3.61  Female     No  Sun  Dinner     4\n","  11        35.26  5.00  Female     No  Sun  Dinner     4\n","  14        14.83  3.02  Female     No  Sun  Dinner     2\n","  16        10.33  1.67  Female     No  Sun  Dinner     3\n","  18        16.97  3.50  Female     No  Sun  Dinner     3\n","  51        10.29  2.60  Female     No  Sun  Dinner     2\n","  52        34.81  5.20  Female     No  Sun  Dinner     4\n","  114       25.71  4.00  Female     No  Sun  Dinner     3\n","  115       17.31  3.50  Female     No  Sun  Dinner     2\n","  155       29.85  5.14  Female     No  Sun  Dinner     5\n","  157       25.00  3.75  Female     No  Sun  Dinner     4\n","  158       13.39  2.61  Female     No  Sun  Dinner     2\n","  162       16.21  2.00  Female     No  Sun  Dinner     3\n","  164       17.51  3.00  Female    Yes  Sun  Dinner     2\n","  178        9.60  4.00  Female    Yes  Sun  Dinner     2\n","  186       20.90  3.50  Female    Yes  Sun  Dinner     3\n","  188       18.15  3.50  Female    Yes  Sun  Dinner     3),\n"," (('Female', 'Thur'),      total_bill   tip     sex smoker   day    time  size\n","  82        10.07  1.83  Female     No  Thur   Lunch     1\n","  85        34.83  5.17  Female     No  Thur   Lunch     4\n","  117       10.65  1.50  Female     No  Thur   Lunch     2\n","  118       12.43  1.80  Female     No  Thur   Lunch     2\n","  119       24.08  2.92  Female     No  Thur   Lunch     4\n","  121       13.42  1.68  Female     No  Thur   Lunch     2\n","  124       12.48  2.52  Female     No  Thur   Lunch     2\n","  125       29.80  4.20  Female     No  Thur   Lunch     6\n","  127       14.52  2.00  Female     No  Thur   Lunch     2\n","  128       11.38  2.00  Female     No  Thur   Lunch     2\n","  131       20.27  2.83  Female     No  Thur   Lunch     2\n","  132       11.17  1.50  Female     No  Thur   Lunch     2\n","  133       12.26  2.00  Female     No  Thur   Lunch     2\n","  134       18.26  3.25  Female     No  Thur   Lunch     2\n","  135        8.51  1.25  Female     No  Thur   Lunch     2\n","  136       10.33  2.00  Female     No  Thur   Lunch     2\n","  137       14.15  2.00  Female     No  Thur   Lunch     2\n","  139       13.16  2.75  Female     No  Thur   Lunch     2\n","  140       17.47  3.50  Female     No  Thur   Lunch     2\n","  143       27.05  5.00  Female     No  Thur   Lunch     6\n","  144       16.43  2.30  Female     No  Thur   Lunch     2\n","  145        8.35  1.50  Female     No  Thur   Lunch     2\n","  146       18.64  1.36  Female     No  Thur   Lunch     3\n","  147       11.87  1.63  Female     No  Thur   Lunch     2\n","  191       19.81  4.19  Female    Yes  Thur   Lunch     2\n","  197       43.11  5.00  Female    Yes  Thur   Lunch     4\n","  198       13.00  2.00  Female    Yes  Thur   Lunch     2\n","  201       12.74  2.01  Female    Yes  Thur   Lunch     2\n","  202       13.00  2.00  Female    Yes  Thur   Lunch     2\n","  203       16.40  2.50  Female    Yes  Thur   Lunch     2\n","  205       16.47  3.23  Female    Yes  Thur   Lunch     3\n","  243       18.78  3.00  Female     No  Thur  Dinner     2),\n"," (('Male', 'Fri'),      total_bill   tip   sex smoker  day    time  size\n","  90        28.97  3.00  Male    Yes  Fri  Dinner     2\n","  91        22.49  3.50  Male     No  Fri  Dinner     2\n","  95        40.17  4.73  Male    Yes  Fri  Dinner     4\n","  96        27.28  4.00  Male    Yes  Fri  Dinner     2\n","  97        12.03  1.50  Male    Yes  Fri  Dinner     2\n","  98        21.01  3.00  Male    Yes  Fri  Dinner     2\n","  99        12.46  1.50  Male     No  Fri  Dinner     2\n","  220       12.16  2.20  Male    Yes  Fri   Lunch     2\n","  222        8.58  1.92  Male    Yes  Fri   Lunch     1\n","  224       13.42  1.58  Male    Yes  Fri   Lunch     2),\n"," (('Male', 'Sat'),      total_bill    tip   sex smoker  day    time  size\n","  19        20.65   3.35  Male     No  Sat  Dinner     3\n","  20        17.92   4.08  Male     No  Sat  Dinner     2\n","  23        39.42   7.58  Male     No  Sat  Dinner     4\n","  24        19.82   3.18  Male     No  Sat  Dinner     2\n","  25        17.81   2.34  Male     No  Sat  Dinner     4\n","  26        13.37   2.00  Male     No  Sat  Dinner     2\n","  27        12.69   2.00  Male     No  Sat  Dinner     2\n","  28        21.70   4.30  Male     No  Sat  Dinner     2\n","  30         9.55   1.45  Male     No  Sat  Dinner     2\n","  31        18.35   2.50  Male     No  Sat  Dinner     4\n","  34        17.78   3.27  Male     No  Sat  Dinner     2\n","  35        24.06   3.60  Male     No  Sat  Dinner     3\n","  36        16.31   2.00  Male     No  Sat  Dinner     3\n","  38        18.69   2.31  Male     No  Sat  Dinner     3\n","  39        31.27   5.00  Male     No  Sat  Dinner     3\n","  40        16.04   2.24  Male     No  Sat  Dinner     3\n","  56        38.01   3.00  Male    Yes  Sat  Dinner     4\n","  58        11.24   1.76  Male    Yes  Sat  Dinner     2\n","  59        48.27   6.73  Male     No  Sat  Dinner     4\n","  60        20.29   3.21  Male    Yes  Sat  Dinner     2\n","  61        13.81   2.00  Male    Yes  Sat  Dinner     2\n","  62        11.02   1.98  Male    Yes  Sat  Dinner     2\n","  63        18.29   3.76  Male    Yes  Sat  Dinner     4\n","  64        17.59   2.64  Male     No  Sat  Dinner     3\n","  65        20.08   3.15  Male     No  Sat  Dinner     3\n","  68        20.23   2.01  Male     No  Sat  Dinner     2\n","  69        15.01   2.09  Male    Yes  Sat  Dinner     2\n","  70        12.02   1.97  Male     No  Sat  Dinner     2\n","  75        10.51   1.25  Male     No  Sat  Dinner     2\n","  76        17.92   3.08  Male    Yes  Sat  Dinner     2\n","  105       15.36   1.64  Male    Yes  Sat  Dinner     2\n","  106       20.49   4.06  Male    Yes  Sat  Dinner     2\n","  107       25.21   4.29  Male    Yes  Sat  Dinner     2\n","  108       18.24   3.76  Male     No  Sat  Dinner     2\n","  110       14.00   3.00  Male     No  Sat  Dinner     2\n","  170       50.81  10.00  Male    Yes  Sat  Dinner     3\n","  171       15.81   3.16  Male    Yes  Sat  Dinner     2\n","  206       26.59   3.41  Male    Yes  Sat  Dinner     3\n","  207       38.73   3.00  Male    Yes  Sat  Dinner     4\n","  208       24.27   2.03  Male    Yes  Sat  Dinner     2\n","  210       30.06   2.00  Male    Yes  Sat  Dinner     3\n","  211       25.89   5.16  Male    Yes  Sat  Dinner     4\n","  212       48.33   9.00  Male     No  Sat  Dinner     4\n","  216       28.15   3.00  Male    Yes  Sat  Dinner     5\n","  217       11.59   1.50  Male    Yes  Sat  Dinner     2\n","  218        7.74   1.44  Male    Yes  Sat  Dinner     2\n","  227       20.45   3.00  Male     No  Sat  Dinner     4\n","  228       13.28   2.72  Male     No  Sat  Dinner     2\n","  230       24.01   2.00  Male    Yes  Sat  Dinner     4\n","  231       15.69   3.00  Male    Yes  Sat  Dinner     3\n","  232       11.61   3.39  Male     No  Sat  Dinner     2\n","  233       10.77   1.47  Male     No  Sat  Dinner     2\n","  234       15.53   3.00  Male    Yes  Sat  Dinner     2\n","  235       10.07   1.25  Male     No  Sat  Dinner     2\n","  236       12.60   1.00  Male    Yes  Sat  Dinner     2\n","  237       32.83   1.17  Male    Yes  Sat  Dinner     2\n","  239       29.03   5.92  Male     No  Sat  Dinner     3\n","  241       22.67   2.00  Male    Yes  Sat  Dinner     2\n","  242       17.82   1.75  Male     No  Sat  Dinner     2),\n"," (('Male', 'Sun'),      total_bill   tip   sex smoker  day    time  size\n","  1         10.34  1.66  Male     No  Sun  Dinner     3\n","  2         21.01  3.50  Male     No  Sun  Dinner     3\n","  3         23.68  3.31  Male     No  Sun  Dinner     2\n","  5         25.29  4.71  Male     No  Sun  Dinner     4\n","  6          8.77  2.00  Male     No  Sun  Dinner     2\n","  7         26.88  3.12  Male     No  Sun  Dinner     4\n","  8         15.04  1.96  Male     No  Sun  Dinner     2\n","  9         14.78  3.23  Male     No  Sun  Dinner     2\n","  10        10.27  1.71  Male     No  Sun  Dinner     2\n","  12        15.42  1.57  Male     No  Sun  Dinner     2\n","  13        18.43  3.00  Male     No  Sun  Dinner     4\n","  15        21.58  3.92  Male     No  Sun  Dinner     2\n","  17        16.29  3.71  Male     No  Sun  Dinner     3\n","  41        17.46  2.54  Male     No  Sun  Dinner     2\n","  42        13.94  3.06  Male     No  Sun  Dinner     2\n","  43         9.68  1.32  Male     No  Sun  Dinner     2\n","  44        30.40  5.60  Male     No  Sun  Dinner     4\n","  45        18.29  3.00  Male     No  Sun  Dinner     2\n","  46        22.23  5.00  Male     No  Sun  Dinner     2\n","  47        32.40  6.00  Male     No  Sun  Dinner     4\n","  48        28.55  2.05  Male     No  Sun  Dinner     3\n","  49        18.04  3.00  Male     No  Sun  Dinner     2\n","  50        12.54  2.50  Male     No  Sun  Dinner     2\n","  53         9.94  1.56  Male     No  Sun  Dinner     2\n","  54        25.56  4.34  Male     No  Sun  Dinner     4\n","  55        19.49  3.51  Male     No  Sun  Dinner     2\n","  112       38.07  4.00  Male     No  Sun  Dinner     3\n","  113       23.95  2.55  Male     No  Sun  Dinner     2\n","  116       29.93  5.07  Male     No  Sun  Dinner     4\n","  150       14.07  2.50  Male     No  Sun  Dinner     2\n","  151       13.13  2.00  Male     No  Sun  Dinner     2\n","  152       17.26  2.74  Male     No  Sun  Dinner     3\n","  153       24.55  2.00  Male     No  Sun  Dinner     4\n","  154       19.77  2.00  Male     No  Sun  Dinner     4\n","  156       48.17  5.00  Male     No  Sun  Dinner     6\n","  159       16.49  2.00  Male     No  Sun  Dinner     4\n","  160       21.50  3.50  Male     No  Sun  Dinner     4\n","  161       12.66  2.50  Male     No  Sun  Dinner     2\n","  163       13.81  2.00  Male     No  Sun  Dinner     2\n","  165       24.52  3.48  Male     No  Sun  Dinner     3\n","  166       20.76  2.24  Male     No  Sun  Dinner     2\n","  167       31.71  4.50  Male     No  Sun  Dinner     4\n","  172        7.25  5.15  Male    Yes  Sun  Dinner     2\n","  173       31.85  3.18  Male    Yes  Sun  Dinner     2\n","  174       16.82  4.00  Male    Yes  Sun  Dinner     2\n","  175       32.90  3.11  Male    Yes  Sun  Dinner     2\n","  176       17.89  2.00  Male    Yes  Sun  Dinner     2\n","  177       14.48  2.00  Male    Yes  Sun  Dinner     2\n","  179       34.63  3.55  Male    Yes  Sun  Dinner     2\n","  180       34.65  3.68  Male    Yes  Sun  Dinner     4\n","  181       23.33  5.65  Male    Yes  Sun  Dinner     2\n","  182       45.35  3.50  Male    Yes  Sun  Dinner     3\n","  183       23.17  6.50  Male    Yes  Sun  Dinner     4\n","  184       40.55  3.00  Male    Yes  Sun  Dinner     2\n","  185       20.69  5.00  Male     No  Sun  Dinner     5\n","  187       30.46  2.00  Male    Yes  Sun  Dinner     5\n","  189       23.10  4.00  Male    Yes  Sun  Dinner     3\n","  190       15.69  1.50  Male    Yes  Sun  Dinner     2),\n"," (('Male', 'Thur'),      total_bill   tip   sex smoker   day   time  size\n","  77        27.20  4.00  Male     No  Thur  Lunch     4\n","  78        22.76  3.00  Male     No  Thur  Lunch     2\n","  79        17.29  2.71  Male     No  Thur  Lunch     2\n","  80        19.44  3.00  Male    Yes  Thur  Lunch     2\n","  81        16.66  3.40  Male     No  Thur  Lunch     2\n","  83        32.68  5.00  Male    Yes  Thur  Lunch     2\n","  84        15.98  2.03  Male     No  Thur  Lunch     2\n","  86        13.03  2.00  Male     No  Thur  Lunch     2\n","  87        18.28  4.00  Male     No  Thur  Lunch     2\n","  88        24.71  5.85  Male     No  Thur  Lunch     2\n","  89        21.16  3.00  Male     No  Thur  Lunch     2\n","  120       11.69  2.31  Male     No  Thur  Lunch     2\n","  122       14.26  2.50  Male     No  Thur  Lunch     2\n","  123       15.95  2.00  Male     No  Thur  Lunch     2\n","  126        8.52  1.48  Male     No  Thur  Lunch     2\n","  129       22.82  2.18  Male     No  Thur  Lunch     3\n","  130       19.08  1.50  Male     No  Thur  Lunch     2\n","  138       16.00  2.00  Male    Yes  Thur  Lunch     2\n","  141       34.30  6.70  Male     No  Thur  Lunch     6\n","  142       41.19  5.00  Male     No  Thur  Lunch     5\n","  148        9.78  1.73  Male     No  Thur  Lunch     2\n","  149        7.51  2.00  Male     No  Thur  Lunch     2\n","  192       28.44  2.56  Male    Yes  Thur  Lunch     2\n","  193       15.48  2.02  Male    Yes  Thur  Lunch     2\n","  194       16.58  4.00  Male    Yes  Thur  Lunch     2\n","  195        7.56  1.44  Male     No  Thur  Lunch     2\n","  196       10.34  2.00  Male    Yes  Thur  Lunch     2\n","  199       13.51  2.00  Male    Yes  Thur  Lunch     2\n","  200       18.71  4.00  Male    Yes  Thur  Lunch     3\n","  204       20.53  4.00  Male    Yes  Thur  Lunch     4)]"]},"metadata":{"tags":[]},"execution_count":48}]},{"cell_type":"markdown","metadata":{"ein.tags":"worksheet-0","id":"LlvxHSGNALa0"},"source":["## Combining dataframes\n","\n","There are many ways to combine various dataframes into a new one, extending in many ways what we already saw for operations on series. The main (among various) ways of doing this are: \n","\n","+ Concatenate: paste row-column-wise and taking action on NaNs\n","    + This works more on the rectangular structure of the data \n","+ Merge: combine dataframes using a common piece of information, e.g. a common column\n","    + This works more as a database operation\n"]},{"cell_type":"markdown","metadata":{"ein.tags":"worksheet-0","id":"ovq98xvVALa0"},"source":["### Concatenate\n","\n","```python\n","pd.concat([df1,df2,...], axis=0) \n","```\n","\n","+ axis: 0 for pasting below, 1 for pasting on the side (order in list matters either way)\n","\n","\n","```\n","\n","What do you think will happen in the following case? \n","\n","```python\n","df1 = pd.DataFrame({\"A\": pd.Series([1,2,3]), \"B\": pd.Series([4,5,6])})\n","df2 = pd.DataFrame({\"A\": pd.Series([4]), \"C\": pd.Series([7])})\n","pd.concat([df1,df2], axis=0)\n","```\n","And what about this code? \n","\n","```python\n","df1 = pd.DataFrame({\"A\": pd.Series([1,2,3]), \"B\": pd.Series([4,5,6])})\n","df2 = pd.DataFrame({\"A\": pd.Series([4]), \"C\": pd.Series([7])})\n","pd.concat([df1,df2],axis = 1,join = \"inner\")\n","```\n","\n","\n"]},{"cell_type":"code","metadata":{"autoscroll":false,"ein.hycell":false,"ein.tags":"worksheet-0","colab":{"base_uri":"https://localhost:8080/","height":166},"id":"Y4OeZ1EiALa0","executionInfo":{"status":"ok","timestamp":1608216496112,"user_tz":-60,"elapsed":1276,"user":{"displayName":"Joan Verdú","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghq6Zm9ACo3kD6kZhp6ZuWkYJqG_DQfPoIV1Ues=s64","userId":"17893353067607712705"}},"outputId":"f7c41c5e-d52c-4644-e824-92886882444a"},"source":["# Concatenation is mostly used when the rows or columns are shared. \n","# For example, you might have data with the same columns and want to concatenate them on axis 0:\n","# But note: what happened to the index? \n","# We might want to reset it. \n","\n","df1 = pd.DataFrame({\"A\": pd.Series([1,2,3]), \"B\": pd.Series([4,5,6])})\n","df2 = pd.DataFrame({\"A\": pd.Series([7]), \"B\": pd.Series([10])})\n","pd.concat([df1,df2], axis=0)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>A</th>\n","      <th>B</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>6</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>7</td>\n","      <td>10</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   A   B\n","0  1   4\n","1  2   5\n","2  3   6\n","0  7  10"]},"metadata":{"tags":[]},"execution_count":51}]},{"cell_type":"code","metadata":{"autoscroll":false,"ein.hycell":false,"ein.tags":"worksheet-0","colab":{"base_uri":"https://localhost:8080/","height":136},"id":"Koj9-bZxALa1","executionInfo":{"status":"ok","timestamp":1608216514853,"user_tz":-60,"elapsed":610,"user":{"displayName":"Joan Verdú","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghq6Zm9ACo3kD6kZhp6ZuWkYJqG_DQfPoIV1Ues=s64","userId":"17893353067607712705"}},"outputId":"7b708283-2ae1-4fb5-a9f3-8eb3db00a17c"},"source":["# Similarly, you might have data with the same rows and different columns:\n","\n","df1 = pd.DataFrame({\"A\": pd.Series([1,2,3]), \"B\": pd.Series([4,5,6])})\n","df2 = pd.DataFrame({\"B\": pd.Series([7,8,9]), \"C\": pd.Series([10,11,12])})\n","pd.concat([df1,df2], axis=1)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>A</th>\n","      <th>B</th>\n","      <th>B</th>\n","      <th>C</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>4</td>\n","      <td>7</td>\n","      <td>10</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>5</td>\n","      <td>8</td>\n","      <td>11</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>6</td>\n","      <td>9</td>\n","      <td>12</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   A  B  B   C\n","0  1  4  7  10\n","1  2  5  8  11\n","2  3  6  9  12"]},"metadata":{"tags":[]},"execution_count":52}]},{"cell_type":"code","metadata":{"autoscroll":false,"ein.hycell":false,"ein.tags":"worksheet-0","colab":{"base_uri":"https://localhost:8080/","height":136},"id":"95AbI1NrALa1","executionInfo":{"status":"ok","timestamp":1608216570008,"user_tz":-60,"elapsed":820,"user":{"displayName":"Joan Verdú","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghq6Zm9ACo3kD6kZhp6ZuWkYJqG_DQfPoIV1Ues=s64","userId":"17893353067607712705"}},"outputId":"0cc7d555-b3e8-47f2-a39a-4443bedbf81e"},"source":["# But note what happens if the rows do not align, and you concatenate on axis 1:\n","\n","df1 = pd.DataFrame({\"A\": pd.Series([1,2,3]), \"B\": pd.Series([4,5,6])})\n","df2 = pd.DataFrame({\"B\": pd.Series([7]), \"C\": pd.Series([10])})\n","pd.concat([df1,df2], axis=1)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>A</th>\n","      <th>B</th>\n","      <th>B</th>\n","      <th>C</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>4</td>\n","      <td>7.0</td>\n","      <td>10.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>5</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>6</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   A  B    B     C\n","0  1  4  7.0  10.0\n","1  2  5  NaN   NaN\n","2  3  6  NaN   NaN"]},"metadata":{"tags":[]},"execution_count":53}]},{"cell_type":"markdown","metadata":{"ein.tags":"worksheet-0","id":"GOQ1rmJxALa1"},"source":["### Merge\n","\n","Merge is commonly used when your two dataframes must be connected and they do not share an index or columns such as when we concatenated. \n","\n","With merge we will connect two DataFrames on some common piece of information, e.g. a common column. The structure of the command is: \n","\n","```python\n","pd.merge(leftdf, rightdf, how = \"inner\", on = , *keywds)  \n","```\n","\n","+ \"on\" defines on what piece of information the DataFrames will merge.\n","+ You can also define \"left_on\" and \"right_on\" separately if the columns are named differently\n","+ There are four options for \"how\", the other important argument in merge:\n","    + \"inner\": intersection of keys\n","    + \"outer\": union of keys\n","    + \"left\": use keys from left only\n","    + \"right\": use keys from right only\n","\n","\n","<img src=\"https://i.stack.imgur.com/hMKKt.jpg\">"]},{"cell_type":"code","metadata":{"autoscroll":false,"ein.hycell":false,"ein.tags":"worksheet-0","id":"7fFVd0o4ALa1","colab":{"base_uri":"https://localhost:8080/","height":77},"executionInfo":{"status":"ok","timestamp":1608216991996,"user_tz":-60,"elapsed":631,"user":{"displayName":"Joan Verdú","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghq6Zm9ACo3kD6kZhp6ZuWkYJqG_DQfPoIV1Ues=s64","userId":"17893353067607712705"}},"outputId":"76c34cbd-b000-40c7-e18e-e5286c85fa51"},"source":["df1 = pd.DataFrame({\"A\": pd.Series([1,2,3]), \"B\": pd.Series([4,5,6])})\n","df2 = pd.DataFrame({\"A\": pd.Series([4]), \"C\": pd.Series([7])})\n","\n","# Let's try merging\n","pd.merge(df1, df2, on='A', how='right')"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>A</th>\n","      <th>B</th>\n","      <th>C</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>4</td>\n","      <td>NaN</td>\n","      <td>7</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   A   B  C\n","0  4 NaN  7"]},"metadata":{"tags":[]},"execution_count":57}]},{"cell_type":"markdown","metadata":{"ein.tags":"worksheet-0","id":"LaecTofyALa1"},"source":["## Working with non-rectangular data\n","\n","We mentioned in the beginning that Pandas is a library for working with rectangular data. \n","\n","What if your data is not rectangular? What does non-rectangular data look like? Very often our data might come in dictionaries. Imagine data about a \"tweet\". It might look like this: \n","\n","\n","```python\n","{\n","    \"screenname\": \"nandanrao\",\n","    \"id_str\": \"928374987\",\n","    \"text\": \"Woah, pandas is so much fun #worldrocked #jawdrop #win\",\n","    \"hashtags\": [\"worldrocked\", \"jawdrop\", \"win\"]\n","}\n","```\n","\n","How would you fit this into a rectangular data format? Do the \"hashtags\" cause a problem? "]},{"cell_type":"code","metadata":{"autoscroll":false,"ein.hycell":false,"ein.tags":"worksheet-0","colab":{"base_uri":"https://localhost:8080/","height":106},"id":"gR7HK7hoALa1","executionInfo":{"status":"ok","timestamp":1608217062802,"user_tz":-60,"elapsed":701,"user":{"displayName":"Joan Verdú","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghq6Zm9ACo3kD6kZhp6ZuWkYJqG_DQfPoIV1Ues=s64","userId":"17893353067607712705"}},"outputId":"344a4e2e-c3eb-4d79-8db9-f57231d73e19"},"source":["raw_tweets = [{ \"screenname\": \"nandanrao\",\n","          \"id_str\": \"928374987\",\n","          \"text\": \"Woah, pandas is so much fun #worldrocked #jawdrop #ml\",\n","          \"hashtags\": [\"worldrocked\", \"jawdrop\", \"ml\"]},\n","          {\"screenname\": \"om\",\n","           \"id_str\": \"98214039\",\n","           \"text\": \"I eat linear models for breakfast #datascience #ml #crossfit\",\n","           \"hashtags\": [\"datascience\", \"ml\", \"crossfit\"]}]\n","\n","tweets = pd.DataFrame(raw_tweets)\n","\n","# What is the \"hashtag\" column made of? \n","tweets"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>screenname</th>\n","      <th>id_str</th>\n","      <th>text</th>\n","      <th>hashtags</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>nandanrao</td>\n","      <td>928374987</td>\n","      <td>Woah, pandas is so much fun #worldrocked #jawd...</td>\n","      <td>[worldrocked, jawdrop, ml]</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>om</td>\n","      <td>98214039</td>\n","      <td>I eat linear models for breakfast #datascience...</td>\n","      <td>[datascience, ml, crossfit]</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  screenname  ...                     hashtags\n","0  nandanrao  ...   [worldrocked, jawdrop, ml]\n","1         om  ...  [datascience, ml, crossfit]\n","\n","[2 rows x 4 columns]"]},"metadata":{"tags":[]},"execution_count":58}]},{"cell_type":"markdown","metadata":{"ein.tags":"worksheet-0","id":"PPxL5V5_ALa1"},"source":["## Merge keeps the data flat\n","\n","The correct way to use data such as this in pandas, data with nested lists, is to copy each tweet to multiple rows, one row for each hashtag. \n","\n","We can use \"merge\" to do this for us automatically if we put the data into two separate dataframes, one for the hashtags and one for the rest of the tweets. This is called \"normalized form\" and is often how you will find data if you get it from a SQL database: "]},{"cell_type":"code","metadata":{"autoscroll":false,"ein.hycell":false,"ein.tags":"worksheet-0","colab":{"base_uri":"https://localhost:8080/","height":110},"id":"xYcWKk1bALa1","executionInfo":{"status":"ok","timestamp":1606739019584,"user_tz":-60,"elapsed":2190,"user":{"displayName":"Joan Verdú","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghq6Zm9ACo3kD6kZhp6ZuWkYJqG_DQfPoIV1Ues=s64","userId":"17893353067607712705"}},"outputId":"7e95e75c-631e-4b1f-9f67-cc6bac8b1db9"},"source":["tweets = pd.DataFrame(raw_tweets, columns = [\"screenname\", \"id_str\", \"text\"])\n","tweets"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>screenname</th>\n","      <th>id_str</th>\n","      <th>text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>nandanrao</td>\n","      <td>928374987</td>\n","      <td>Woah, pandas is so much fun #worldrocked #jawd...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>om</td>\n","      <td>98214039</td>\n","      <td>I eat linear models for breakfast #datascience...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  screenname     id_str                                               text\n","0  nandanrao  928374987  Woah, pandas is so much fun #worldrocked #jawd...\n","1         om   98214039  I eat linear models for breakfast #datascience..."]},"metadata":{"tags":[]},"execution_count":40}]},{"cell_type":"code","metadata":{"autoscroll":false,"ein.hycell":false,"ein.tags":"worksheet-0","colab":{"base_uri":"https://localhost:8080/","height":233},"id":"qVj-kq58ALa1","executionInfo":{"status":"ok","timestamp":1606739019585,"user_tz":-60,"elapsed":2185,"user":{"displayName":"Joan Verdú","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghq6Zm9ACo3kD6kZhp6ZuWkYJqG_DQfPoIV1Ues=s64","userId":"17893353067607712705"}},"outputId":"1406f213-9ffa-49f7-a503-3ab17d9a2b97"},"source":["tags_and_ids = [(t['id_str'], tag) \n","                for t in raw_tweets \n","                for tag in t['hashtags']]\n","\n","hashtags = pd.DataFrame(tags_and_ids, columns = ['id_str', 'hashtag'])\n","\n","hashtags"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id_str</th>\n","      <th>hashtag</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>928374987</td>\n","      <td>worldrocked</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>928374987</td>\n","      <td>jawdrop</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>928374987</td>\n","      <td>ml</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>98214039</td>\n","      <td>datascience</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>98214039</td>\n","      <td>ml</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>98214039</td>\n","      <td>crossfit</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      id_str      hashtag\n","0  928374987  worldrocked\n","1  928374987      jawdrop\n","2  928374987           ml\n","3   98214039  datascience\n","4   98214039           ml\n","5   98214039     crossfit"]},"metadata":{"tags":[]},"execution_count":41}]},{"cell_type":"markdown","metadata":{"id":"JgBsT38i5uzB"},"source":["### Exercise 8"]},{"cell_type":"code","metadata":{"autoscroll":false,"ein.hycell":false,"ein.tags":"worksheet-0","id":"0a7do1hiALa1"},"source":["# Challenge: try to put the two separate dataframes together!\n","# HINT: We want the dataframe to be in \"long\" format. \n","# Lookup \"long vs. wide data\" for more information. \n"],"execution_count":null,"outputs":[]}]}